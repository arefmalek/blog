---
layout: post
title: Airdraw
date: 2021-11-15
categories: computer_vision
---

I've been really into Computer Vision for a while (especially on the Deep
Learning side), but I've began to realize I never really did explored the
fundamental image-processing side of CV. I've been peeping the [mediapipe](https://github.com/google/mediapipe)
project done at Google, and I knew I wanted to make something with it. 

What did I end up making? [Airdraw](https://github.com/arefmalek/airdraw)!
I'd be lying if I said it was the most expansive CV project conceived, but it's
been a ton of fun to work on, especially as I got to bring together math I've
learned in class with the CS stuff I love to do. I'll start to write about the
big chunks of the project below.


## just a quick demo
![Me trying the hands](../assets/airdraw/demo.gif)


## Overall layout
This was one of the last things I really worked on, as the challenge was really
converting an image of someone's hand into a line being drawn. That being said,
I still had to figure out what sort of layout I wanted. 

I ended up choosing a layout where we choose colors and have a hard reset
button. I chose this because it aligns really well with the way I approached
the problem right now as well as a basic layout. This scales really nicely
because if we look at the gif about, you can see that the 3 colors we demo'd
there could increase to 5, 10, etc., and we could dynamically resize.

Right now, I'm sticking with three colors (R,G,B - fitting for a CV project
after all) and a clear output function so that someone can always have a clean
canvas.

## How do we draw?
The point of Airdraw was to have a canvas on demand, and with MediaPipe making
it so easy to get the metadata from my hand, I just needed to come up with some
convention of alignment between my fingers to signify I'm in 'drawing' mode vs.
not. I ended up going with the convention of index finger up meaning draw, two
fingers up indicating I'm 'pausing' the drawing (basically I'm not in drawing
mode - I called this "hover" mode). 

I had waypoints along my hand, so what I ended up doing here to make it
work is that I am making one vector along my index finger, and another vector
along my middle finger. With two separate vectors, I could measure how
'colinear' they were by using the dot product of the two vectors. I won't dive
into multivariable calculus / linear algebra here, but the 
[dot product](https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/x786f2022:vectors-and-matrices/a/dot-products-mvc) 
of two vectors essentially shows you how 'similar' two lines are. With some
simple algebra, I can get the angle between my index and middle finger. All
I wrote the code to do was to check if my index and middle finger have a dot
product that is near 1 - which would indicate drawing - and if not that means
my fingers are close together. It's probably best shown with an example.

![Demo of my fingers and dot product](../assets/airdraw/dotproduct.gif)

Notice how the dot product increases as my fingers come together, this
essentially is just the cosine of the angle between my fingers is approaching
1 (and therefore the angle between my two fingers approaches 0).

## Converting fingerpoints to lines
This was one of the larger problems of the project, and something that I did
have to start breaking out more classes for. I essentially treated the frame as
a canvas, and the way I would start to convert my finger data onto lines and
the color associated with them. The next layer of abstraction is to hold all of
the lines in a queue and iterate through them to draw separate lines.

This may seem like overkill to explain how to draw a few lines, but it's
important to mention because each of the lines, circles, or any other shape is
it's own entity, and needs a class dedicated to it (at least in the easiest
implementation). 
